{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7eeda2b",
   "metadata": {},
   "source": [
    "### Modelo de Machine Learning para la classificación de tumores malignos\n",
    "\n",
    " Se presenta el proceso de entrenamiento de una Regresión Logística para la classificación de tumores. La base de datos fue obtenida de UCI Machine Learning Repository \n",
    "URL: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "\n",
    " Se busca realizar la correcta clasificación de tumores malignos y benignos a partir de las características de los tumores. Este es un problema de clasificación binaria donde se busca predecir si un tumor es maligno o benigno a partir de las características de los tumores. Para cumplir con este objetivo se utiliza un modelo de Regresión Logística. \n",
    "\n",
    "## Regresión Logística para Clasificación\n",
    "\n",
    "La regresión logística es un algoritmo de aprendizaje supervisado que se utiliza principalmente para problemas de clasificación, donde el objetivo es predecir una variable categórica o de clase en función de una o más variables independientes. Aunque el nombre incluye la palabra \"regresión\", la regresión logística no se utiliza para predecir valores continuos, sino para estimar la probabilidad de que una instancia pertenezca a una de las dos o más clases posibles. Es ampliamente utilizada en aplicaciones de clasificación binaria, pero también se puede extender a problemas de clasificación multiclase.\n",
    "\n",
    "### Conceptos Clave\n",
    "\n",
    "1. **Variables Independientes**: En un problema de clasificación, tienes un conjunto de variables independientes (también llamadas características o atributos) que se utilizan para hacer la predicción. Cada instancia de datos se representa como un vector de características, denotado como $X$.\n",
    "\n",
    "2. **Variable Dependiente**: La variable que deseas predecir se llama la variable dependiente o la variable de respuesta, denotada como $Y$. En la regresión logística, $Y$ es una variable categórica binaria o multiclase. En el caso de clasificación binaria, $Y$ puede tomar valores como 0 o 1, que representan dos clases diferentes.\n",
    "\n",
    "3. **Modelo Logístico**: La regresión logística utiliza una función logística (también llamada función sigmoide) para modelar la relación entre las variables independientes y la probabilidad de pertenecer a una clase particular. La función logística es una función sigmoide, que toma cualquier valor real y produce un valor entre 0 y 1. La función logística se define como:\n",
    "\n",
    "    $P(Y=1|X)$ = $\\frac{1}{1+e^{-\\beta X}}$\n",
    "\n",
    "4. **Entrenamiento del Modelo**: El objetivo del entrenamiento es encontrar los mejores valores para los coeficientes $\\beta$ de modo que el modelo se ajuste adecuadamente a los datos de entrenamiento. Esto generalmente se hace utilizando técnicas de optimización, como el descenso de gradiente.\n",
    "\n",
    "5. **Predicción**: Una vez que el modelo está entrenado, puedes usarlo para predecir la probabilidad de que una nueva instancia pertenezca a una clase específica. Si la probabilidad es mayor que un umbral (generalmente 0.5 en problemas binarios), se asigna a la clase positiva; de lo contrario, se asigna a la clase negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ba3ad2-cacf-40d0-b7be-74e6ea5502ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c38242e-f9c0-4046-8b59-440a25b3788f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lbl</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  lbl  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0      842302    1        17.99         10.38          122.80     1001.0   \n",
       "1      842517    1        20.57         17.77          132.90     1326.0   \n",
       "2    84300903    1        19.69         21.25          130.00     1203.0   \n",
       "3    84348301    1        11.42         20.38           77.58      386.1   \n",
       "4    84358402    1        20.29         14.34          135.10     1297.0   \n",
       "..        ...  ...          ...           ...             ...        ...   \n",
       "564    926424    1        21.56         22.39          142.00     1479.0   \n",
       "565    926682    1        20.13         28.25          131.20     1261.0   \n",
       "566    926954    1        16.60         28.08          108.30      858.1   \n",
       "567    927241    1        20.60         29.33          140.10     1265.0   \n",
       "568     92751    0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  worst radius  worst texture  worst perimeter  worst area  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main=pd.read_csv('wdbc.data',encoding = 'unicode_escape', engine ='python')\n",
    "df_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d462548",
   "metadata": {},
   "source": [
    "#### El data set cuenta con 569 registros, tiene 32 variables (ID, diagnóstico, 30 características de entrada de valor real) \n",
    "\n",
    "#### Información sobre los atributos\n",
    "\n",
    "\t1. Número de identificación\n",
    "\t2. Diagnóstico (M = maligno, B = benigno)\n",
    "\t3-32.\n",
    "\tSe calculan diez características de valor real para cada núcleo celular:\n",
    "\t\n",
    "\ta. radio (media de las distancias del centro a los puntos del perímetro)\n",
    "\tb. textura (desviación estándar de los valores en escala de grises)\n",
    "\tc. perímetro\n",
    "\td. área\n",
    "\te. suavidad (variación local de las longitudes de los radios)\n",
    "\tf. compacidad (perímetro^2 / área - 1,0)\n",
    "\tg. concavidad (gravedad de las partes cóncavas del contorno)\n",
    "\th. puntos cóncavos (número de porciones cóncavas del contorno)\n",
    "\ti. simetría \n",
    "\tj. dimensión fractal (\"aproximación de la línea de costa\" - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85688fc0-490e-4951-9eab-e1406ee3c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.lbl= df_main.lbl.replace({'M':1,'B':0})\n",
    "df = df_main\n",
    "df = df.drop(['id','lbl'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf46fc",
   "metadata": {},
   "source": [
    "#### Se divide al set en un set de entrenamiento y un set de prueba. El set de entrenamiento se utiliza para entrenar el modelo y el set de prueba para evaluar el modelo. Se utiliza un 80% de los datos para entrenamiento y un 20% para prueba. También se realiza un escalamiento de los datos para que todas las variables tengan la misma escala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5138063-141b-494d-9831-b504793163db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train , y_test = train_test_split(df,df_main.lbl,test_size=0.2)#, random_state=42)\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "\n",
    "x_train_t=scaler.transform(x_train)\n",
    "x_test_t=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69991c",
   "metadata": {},
   "source": [
    "#### Se declaran los hiperparámetros del modelo los cuales son principalmente el número de iteraciones y el tamaño del paso o learning rate. Se utiliza un learning rate de 0.1 y 1000 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "550d3524-ad97-43fc-950d-4228a21a36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = lambda x,theta0,theta : 1/(1+np.exp(-(theta0+np.sum(theta.T*x))))\n",
    "\n",
    "v=len(df.columns)\n",
    " \n",
    "n = len(x_train.iloc[0])\n",
    "n_it = 10000 #numero de iteraciones\n",
    "alph = 0.1 #learning rate\n",
    "\n",
    "t0 = 0\n",
    "t = np.random.rand(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813758a8",
   "metadata": {},
   "source": [
    "#### Se entrena el modelo con los datos de entrenamiento y se evalúa el modelo con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc18cbf8-442d-4653-ae5f-5fd4adb9b7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.141137920832857\n",
      "[ 0.83745944  1.79756958  1.70595818  0.200252    0.69068627  0.73029087\n",
      "  1.1329084   0.60858471 -1.4538311  -0.75468216  0.72027937 -0.85502556\n",
      "  0.27096811  0.96289336 -2.55497051  4.03547005  2.7395282   4.69515237\n",
      " -3.4006924  -0.17189632 -0.81535694  0.91653498 -0.62472428 -1.40057692\n",
      " -4.25019539 -0.98643083 -0.78836811 -4.49598661 -0.32640908 -1.05819277]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,n_it-1):\n",
    "    d = np.zeros((n,v))\n",
    "    d0 = []\n",
    "  # Barrer muestras\n",
    "    for j in range(0,n):\n",
    "        # Calcular delta para theta0 y para cada muestra\n",
    "        d0.append(h(x_train_t[j,:],t0,t)-df_main['lbl'].iloc[j])\n",
    "    # Calcular delta para theta1 y para cada muestra\n",
    "        d[j,:] = x_train_t[j,:].T*(h(x_train_t[j,:],t0,t)-df_main['lbl'].iloc[j])\n",
    "\n",
    "  # Calcular sumatorias y promedio\n",
    "    t0 = t0 - alph*(sum(d0)/n)\n",
    "    t = t - np.sum(d,axis=0).T*(alph/n)\n",
    "\n",
    "# Imprimir theta actualizado\n",
    "print(t0)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6c123e8-781f-42d9-8314-9a26fa858d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(0,len(y_test)):\n",
    "    pred.append(round(h(x_test_t[i,:],t0,t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd6778fd-d8c1-4ad8-8a47-4ea7890ff8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f038d54-fdfb-418b-a573-7b2150f5e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test.reset_index(drop=True)#.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "21f60ec8-224b-423e-8e0a-caa3239c1d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VP = sum(pred * y) #verdaderos positivos\n",
    "VN = len(pred[(pred == 0) * (pred == y)]) #verdaderos negativos\n",
    "FP = len(pred[(pred == 1) * (pred != y)]) #falsos positivos\n",
    "FN = len(pred[(pred == 0) * (pred != y)]) #falsos negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d490c78",
   "metadata": {},
   "source": [
    "#### Evaluación del modelo utilizando metricas de clasificación accuracy y matriz de confusión. Estas metricas son calculadas a partir de las predicciones hechas por el modelo y los valores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "012802e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3508771929824561\n",
      "Confusion Matrix:\n",
      "[[ 1 74]\n",
      " [ 0 39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy = accuracy_score(y, pred)\n",
    "confusion_mat = confusion_matrix(y, pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d91b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
